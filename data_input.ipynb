import tensorflow_addons as tfa
import numpy as np
import pandas as pd
import tensorflow as tf
import os
import keras.backend as K
import math

window_size = 168
batch_size = 100
shuffle_buffer = 20000 #greater than or equal to dataset
train , valid =  157715, 182715  #train 80%, valid 25k, train 10k 
prediction_steps = 24

def windowed_dataset(data, window_size, batch_size, shuffle_buffer,max_rhum,min_rhum):
    dataset = tf.data.Dataset.from_tensor_slices(data) #take each row and slice
    dataset = dataset.window(window_size + 24, shift=1, drop_remainder=True) # +1 is the prediction
    dataset = dataset.flat_map(lambda window: window.batch(window_size + 24))
    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-24], (window[-24:]*(max_rhum-min_rhum))+ min_rhum))
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

def step_decay(epoch):
    drop = 0.7
    epochs_drop = 10.0
    lrate = 7e-4 * math.pow(drop,  
           math.floor((1+epoch)/epochs_drop)) 
    return lrate

def custom(epoch, lr):
    return lr/(epoch+1)

class printLearningRate(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        optimizer = self.model.optimizer
        lr = K.eval(optimizer.lr)
        lr_dict[epoch] = lr
        Epoch_count = epoch + 1
        print('\n', "Epoch:", Epoch_count, ', LR: {:.8f}'.format(lr))

tensor5d2f = np.load('tensor5D-10by10-RhumGHI.npy')
univariate_non_spatial_data = tensor5d2f[:,0,4,4] #19th station of -6 (ID: 878848)
maxrhum= max(univariate_non_spatial_data)
minrhum = min(univariate_non_spatial_data)
univariate_non_spatial_data = (univariate_non_spatial_data-minrhum)/(maxrhum-minrhum)

rhum_train = univariate_non_spatial_data[:train]
rhum_train = rhum_train.reshape((157715,1))

rhum_valid = univariate_non_spatial_data[train:valid]
rhum_valid = rhum_valid.reshape((25000,1))

rhum_test = univariate_non_spatial_data[valid:]
rhum_test = rhum_test.reshape((10000,1))
assert len(rhum_train) + len(rhum_valid) + len(rhum_test) ==  len(univariate_non_spatial_data)

rhum_train_window = windowed_dataset(rhum_train, window_size,batch_size,shuffle_buffer,maxrhum,minrhum)
rhum_valid_window = windowed_dataset(rhum_valid, window_size,batch_size,shuffle_buffer,maxrhum,minrhum)
rhum_test_window = windowed_dataset(rhum_test, window_size,batch_size,shuffle_buffer,maxrhum,minrhum)
